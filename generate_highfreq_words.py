# generate_highfreq_words.py
import os
import pandas as pd
import jieba
from collections import Counter

INPUT_CSV = "dataset/articles.csv"
OUTPUT_CSV = "config/highfreq_words.csv"
TOP_N = 500

# è®€å–èªæ–™
df = pd.read_csv(INPUT_CSV)
texts = df["content"].dropna().astype(str).tolist()
print(f"ğŸ“„ å…±è®€å…¥ {len(texts)} ç¯‡æ–‡ç« ")

# jieba æ–·è©ä¸¦çµ±è¨ˆè©é »
counter = Counter()
for text in texts:
    words = jieba.lcut(text)
    words = [w.strip() for w in words if len(w.strip()) >= 2]
    counter.update(words)

# å–å‰ N é«˜é »è©
most_common = counter.most_common(TOP_N)
df_out = pd.DataFrame(most_common, columns=["word", "count"])
os.makedirs("config", exist_ok=True)
df_out.to_csv(OUTPUT_CSV, index=False, encoding="utf-8-sig")
print(f"âœ… å·²å„²å­˜å‰ {TOP_N} é«˜é »è©è‡³ï¼š{OUTPUT_CSV}")
